{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%reset -f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pyreadr\n",
    "from tensorflow import keras\n",
    "from keras.applications.resnet_v2 import ResNet50V2, ResNet152V2, preprocess_input, decode_predictions\n",
    "from keras.applications.resnet50 import ResNet50, preprocess_input, decode_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pyreadr.read_r('df_002.rda')\n",
    "result2 = pyreadr.read_r('df2_002.rda')\n",
    "result3 = pyreadr.read_r('c3_002.rda')\n",
    "result4 = pyreadr.read_r('df_max_002.rda')\n",
    "result5 = pyreadr.read_r('df_min_002.rda')\n",
    "result6 = pyreadr.read_r('n_002.rda')\n",
    "\n",
    "print(result.keys())\n",
    "print(result2.keys())\n",
    "print(result3.keys())\n",
    "print(result4.keys())\n",
    "print(result5.keys())\n",
    "print(result6.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = result[\"df\"]\n",
    "df2 = result2[\"df2\"]\n",
    "c3 = result3[\"c3\"]\n",
    "df_max = result4[\"df_max\"]\n",
    "df_min = result5[\"df_min\"]\n",
    "n = result6[\"n\"]\n",
    "print(df_max)\n",
    "print(df_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r, n_road = c3.shape\n",
    "print(n_road)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_lookback = 24\n",
    "n_sample = int(len(df)/(n_road) - n_lookback)\n",
    "n_time = 1\n",
    "channel = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "  \n",
    "X_mat = np.zeros([n_sample, n_road, n_lookback, channel], dtype = float)\n",
    "Y_mat = np.zeros([n_sample, n_road], dtype = float)\n",
    "# print(\"Matrix b : \\n\", b)\n",
    "print(X_mat.shape)\n",
    "print(Y_mat.shape)\n",
    "print(type(X_mat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in (number for number in range(n_sample)):\n",
    "    for j in (number for number in range(n_lookback)):\n",
    "        st = (j+i)*(n_road) + 1\n",
    "        en = ((j+i)+1)*(n_road)\n",
    "        st = st - 1\n",
    "        en = en - 1\n",
    "        X_mat[i,:,j,2] = df[st:(en+1)].to_numpy().flatten()\n",
    "    \n",
    "    st2 = (i+n_lookback)*(n_road)\n",
    "    en2 = (i+n_lookback+1)*(n_road)\n",
    "    Y_mat[i,:] = df[st2:(en2)].to_numpy().flatten()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Input, Activation\n",
    "from keras.models import Model\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras import optimizers\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "epochs = [5, 10]\n",
    "input = Input(shape=(n_road, n_lookback, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for p in (number for number in range(len(epochs))):\n",
    "    print(epochs[p])\n",
    "    base_model = ResNet152V2(input_tensor = input, include_top = False, weights = \"imagenet\")\n",
    "    x = base_model(input, training=False)\n",
    "    model = Sequential([\n",
    "      base_model,\n",
    "      keras.layers.GlobalAveragePooling2D(),\n",
    "#       keras.layers.Dense(128, activation = 'relu'),\n",
    "#       keras.layers.Dense(128, activation = 'relu'),\n",
    "#       keras.layers.Dense(128, activation = 'relu'),\n",
    "      keras.layers.Flatten(),\n",
    "      keras.layers.Dense(n_road)\n",
    "    ])\n",
    "    # model.summary()\n",
    "    model.compile(optimizer=keras.optimizers.Adam(),\n",
    "                  loss='mean_absolute_error',)\n",
    "\n",
    "    model.fit(X_mat, Y_mat, epochs = epochs[p]) \n",
    "    n_road2 = n_road\n",
    "    n_lookback2 = n_lookback\n",
    "    n_sample2 = int(len(df2)/(n_road2) - n_lookback2)\n",
    "    n_time2 = 1\n",
    "    X_mat2 = np.zeros([n_sample2, n_road2, n_lookback2, channel], dtype = float)\n",
    "    Y_mat2 = np.zeros([n_sample2, n_road2], dtype = float)\n",
    "  \n",
    "    # print(\"Matrix b : \\n\", b)\n",
    "    print(X_mat2.shape)\n",
    "    print(Y_mat2.shape)\n",
    "    print(type(X_mat2))\n",
    "    \n",
    "    for k in (number for number in range(n_sample2)):\n",
    "        for l in (number for number in range(n_lookback2)):\n",
    "    #         if j == 0 and i == 0:\n",
    "    #             st = 0\n",
    "    #             en = ((j+i)+1)*(n_road-1)\n",
    "    #         else:\n",
    "            st3 = (l+k)*(n_road2) + 1\n",
    "            en3 = ((l+k)+1)*(n_road2)\n",
    "            st3 = st3 - 1\n",
    "            en3 = en3 - 1\n",
    "\n",
    "            X_mat2[k,:,l,2] = df2[st3:(en3+1)].to_numpy().flatten()\n",
    "\n",
    "        st4 = (k+n_lookback2)*(n_road2)\n",
    "        en4 = (k+n_lookback2+1)*(n_road2)\n",
    "        Y_mat2[k,:] = df[st4:(en4)].to_numpy().flatten()\n",
    "        \n",
    "    y_pred = model(X_mat2).numpy()\n",
    "        \n",
    "    preds2 = (y_pred*(df_max.to_numpy().flatten() - df_min.to_numpy().flatten())) + df_min.to_numpy().flatten()\n",
    "        \n",
    "\n",
    "    Y_mat2 = (Y_mat2*(df_max.to_numpy().flatten() - df_min.to_numpy().flatten())) + df_min.to_numpy().flatten()\n",
    "\n",
    "    \n",
    "    # pip install sklearn\n",
    "    from sklearn.metrics import mean_absolute_error\n",
    "    mae = mean_absolute_error(preds2, Y_mat2)\n",
    "    \n",
    "    preds2max = preds2.max()\n",
    "    preds2min = preds2.min()\n",
    "    \n",
    "    tests = [\"model_002_152_nadd\" + str(epochs[p]) + \".pkl\"]\n",
    "    import pickle\n",
    "    with open(tests[0], 'wb') as f:  \n",
    "        pickle.dump([mae, preds2max, preds2min], f)\n",
    "\n",
    "    # Getting back the objects:\n",
    "    with open(tests[0], 'rb') as f:  # Python 3: open(..., 'rb')\n",
    "        mae, preds2max, preds2min = pickle.load(f)\n",
    "    \n",
    "    tests = [\"model/model_002_152_nadd\" + str(epochs[p]) + \".h5\"]\n",
    "    model.save(tests[0])\n",
    "    print(mae, preds2max, preds2min)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
